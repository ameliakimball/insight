{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) is 0.6979923109782145\n",
      "f1 of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) is 0.8035069102301725\n",
      "Accuracy of SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) is 0.701254320220574\n",
      "f1 of SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) is 0.8041147862399104\n",
      "Accuracy of DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') is 0.7004776513533455\n",
      "f1 of DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') is 0.7967749585013042\n",
      "Accuracy of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) is 0.701720321540911\n",
      "f1 of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) is 0.7997601605881279\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "petdat = pd.read_csv('backup_petdata_Jan30.csv')\n",
    "\n",
    "moddat = petdat[['coat',\n",
    "                 'age',\n",
    "                 'size',\n",
    "                 'top_ten',\n",
    "                 'contact.address.state',\n",
    "                 'attributes.special_needs',\n",
    "                 'environment.children',\n",
    "                 'environment.dogs',\n",
    "                 'environment.cats',\n",
    "                 'bin_month_target']]\n",
    "\n",
    "\n",
    "cols_to_transform = ['coat',\n",
    "                     'age',\n",
    "                     'size',\n",
    "                     'top_ten',\n",
    "                     'contact.address.state',\n",
    "                     'attributes.special_needs',\n",
    "                     'environment.children',\n",
    "                     'environment.dogs',\n",
    "                     'environment.cats']\n",
    "\n",
    "\n",
    "moddat = pd.get_dummies(moddat, columns = cols_to_transform)\n",
    "\n",
    "X = moddat.drop(columns = ['bin_month_target'])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, moddat.bin_month_target, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "model1 = xgboost.XGBClassifier()\n",
    "classifiers.append(model1)\n",
    "model2 = svm.SVC()\n",
    "classifiers.append(model2)\n",
    "model3 = tree.DecisionTreeClassifier()\n",
    "classifiers.append(model3)\n",
    "model4 = RandomForestClassifier()\n",
    "classifiers.append(model4)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    #roc_auc = roc_auc_score(y_test,y_pred)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    print(\"f1 of %s is %s\"%(clf, f1))\n",
    "    \n",
    "\n",
    "#Implemented in other files:\n",
    "#Random forest \n",
    "#Logistic Regression,\n",
    "\n",
    "#not yet implemented: \n",
    "#Naive Bayes \n",
    "#K-Nearest Neighbor\n",
    "\n",
    "\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "  #  print(\"Confusion Matrix of %s is %s\"%(clf, cm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
